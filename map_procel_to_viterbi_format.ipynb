{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname, abspath, join as pjoin\n",
    "from os import makedirs, mkdir\n",
    "import scipy.io as sio\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('/Users/ryangreen/Desktop/Procedure Learning Research/cygnus_data/ProceL/change_iphone_battery/data.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### CREATE DIRECTORIES TO STORE ALL PRODUCED FEATURES\n",
    "\n",
    "output_path = \"/Users/ryangreen/Desktop/Procedure Learning Research/mapped_procel\"\n",
    "directory_name = \"change_iphone_battery\"\n",
    "bkgrd_class_label = \"BKGRD\"\n",
    "\n",
    "full_directory_path = pjoin(output_path, directory_name)\n",
    "transcript_dir_path = pjoin(full_directory_path, \"transcripts\")\n",
    "gt_dir_path = pjoin(full_directory_path, \"groundTruth\")\n",
    "feature_dir_path = pjoin(full_directory_path, \"features\")\n",
    "\n",
    "for directory in [full_directory_path, transcript_dir_path, gt_dir_path, feature_dir_path]:\n",
    "    try:\n",
    "        makedirs(directory)\n",
    "    except FileExistsError as e:\n",
    "        print (\"ERROR - Creation of the directory %s failed: %s \\n\" % (directory, e.strerror))\n",
    "    else:\n",
    "        print (\"SUCCESS - Created %s\" % directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE MAPPING FILE FOR KEYSTEPS TO INDICES ###\n",
    "mapping_arr = ['0 ' + bkgrd_class_label] + [str(count + 1) + ' ' + name[0].replace(\" \", \"_\") for count, name in enumerate(data['grammar'][:,0])]\n",
    "mapping_file = open(full_directory_path + \"/mapping.txt\",\"w\")\n",
    "mapping_file.writelines(\"\\n\".join(mapping_arr))\n",
    "mapping_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_to_transcript(arr):\n",
    "    out = []\n",
    "    for i in range(len(arr)):\n",
    "        if i == 0 or arr[i - 1] != arr[i]:\n",
    "            out.append(arr[i])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAP SUPERFRAME KEYSTEP INTERVALS TO TRANSCRIPTS AND GT TEXT FILES ###\n",
    "\n",
    "video_idx = 0\n",
    "for video in data['key_steps'][:,0]:\n",
    "    steps = [step_range.tolist() for step_range in video[:,0]]\n",
    "    \n",
    "    # make superframe mapping to all background class 'SIL'\n",
    "    num_superframes = data['superframe_frame'][video_idx][0].shape[0]\n",
    "    groundtruth = [bkgrd_class_label] * num_superframes\n",
    "    \n",
    "#     print('\\n### Video ' + str(video_idx) + ' ' + str(num_superframes) + '\\n')\n",
    "    \n",
    "    for step_idx in range(len(steps)):\n",
    "        step = steps[step_idx]\n",
    "        key_step_name = data['grammar'][:,0][step_idx][0].replace(\" \", \"_\")\n",
    "        \n",
    "        for segment in step:\n",
    "            if len(segment) == 2:\n",
    "#                 print(\"Interval:\" + str(segment))\n",
    "                for sf_idx in range(segment[0], segment[1] + 1):\n",
    "#                     print(sf_idx)\n",
    "                    if sf_idx < num_superframes: # shouldn't need - check with Zijia\n",
    "                        groundtruth[sf_idx] = key_step_name\n",
    "    \n",
    "    transcript = reduce_to_transcript(groundtruth)\n",
    "            \n",
    "    video_name = directory_name + \"_\" + str(video_idx).zfill(4)\n",
    "    \n",
    "    np.save( feature_dir_path + \"/\" + video_name, np.concatenate((data['feature_hofs_sf'][video_idx][0], data['feature_vgg'][video_idx][0]), axis=0))\n",
    "    \n",
    "    \n",
    "    # write out groundtruth\n",
    "    output_file = open(gt_dir_path + \"/\" + video_name + \".txt\",\"w\") \n",
    "    output_file.writelines(\"\\n\".join(groundtruth))\n",
    "    output_file.close()\n",
    "    \n",
    "    # reduce groundtruth array to transcript\n",
    "    output_file = open(transcript_dir_path + \"/\" + video_name + \".txt\",\"w\") \n",
    "    output_file.writelines(\"\\n\".join(transcript))\n",
    "    output_file.close()\n",
    "    \n",
    "    video_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_video_features(features):\n",
    "    return np.concatenate([video_features for video_features in features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_and_transform_features(reduced_feature_dim, output_dir_path, make_directory=True):\n",
    "\n",
    "    if make_directory: mkdir(output_dir_path)\n",
    "    \n",
    "    num_videos = data['feature_hofs_sf'].shape[0]\n",
    "    hofs_features = data['feature_hofs_sf'][:,0]\n",
    "    vgg_features = data['feature_vgg'][:,0]\n",
    "\n",
    "    if num_videos != len(vgg_features):\n",
    "        print('Num videos does not match features', num_videos, len(hofs_features), len(vgg_features))\n",
    "        return\n",
    "\n",
    "    # concatenate vgg and hofs_sf features\n",
    "    combined_features = [None] * num_videos\n",
    "    \n",
    "    for video_idx in range(num_videos):\n",
    "        combined_features[video_idx] = np.concatenate((hofs_features[video_idx], vgg_features[video_idx]), axis=0)\n",
    "    \n",
    "    \n",
    "    # compute transformation matrix\n",
    "    pca = PCA(n_components=reduced_feature_dim)\n",
    "    # flatten and transform data to be (num_features)\n",
    "    flat_features = np.swapaxes(flatten_video_features(combined_features), 0, 1)\n",
    "    pca.fit(flat_features)\n",
    "    \n",
    "    for video_idx in range(num_videos):\n",
    "        transformed_vid_features = np.swapaxes(pca.transform(np.swapaxes(combined_features[video_idx], 0, 1)), 0, 1)\n",
    "        video_name = directory_name + \"_\" + str(video_idx).zfill(4)\n",
    "        np.save( output_dir_path + \"/\" + video_name, transformed_vid_features)\n",
    "    \n",
    "    return pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_var = reduce_and_transform_features(300, pjoin(feature_dir_path, '300_features'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "var1=np.round(np.cumsum(explained_var * 100), decimals=4)\n",
    "\n",
    "plt.plot(var1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
